{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemon のモジュールを利用して、Malleganモデルを作成する\n",
    "\n",
    "mellegan model は RandaomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_out_root_dir = \"../../data/lemon/datasets\"\n",
    "model_out_root_dir = \"../../data/lemon/model/magellan\"\n",
    "dataset_names = [\n",
    "    \"structured_amazon_google\",\n",
    "    \"structured_beer\",\n",
    "    \"structured_dblp_acm\",\n",
    "    \"structured_dblp_google_scholar\",\n",
    "    \"structured_fodors_zagat\",\n",
    "    \"structured_walmart_amazon\",\n",
    "    \"structured_itunes_amazon\",\n",
    "    \"dirty_dblp_acm\",\n",
    "    \"dirty_dblp_google_scholar\",\n",
    "    \"dirty_walmart_amazon\",\n",
    "    \"dirty_itunes_amazon\",\n",
    "    \"textual_abt_buy\",\n",
    "    \"textual_company\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can not save and load the model created MalleganMatcher in lemon\n",
    "# So, patching with these codes for saving and loading model file\n",
    "\n",
    "\n",
    "# Magellan imports Tkinter, but we don't need it for our case\n",
    "class DummyTkinterFrame:\n",
    "    ...\n",
    "\n",
    "\n",
    "class DummyTkinter:\n",
    "    Frame = DummyTkinterFrame\n",
    "\n",
    "import sys\n",
    "sys.modules[\n",
    "    \"Tkinter\"\n",
    "] = DummyTkinter\n",
    "\n",
    "import py_entitymatching.feature.autofeaturegen\n",
    "del sys.modules[\"Tkinter\"]\n",
    "\n",
    "\n",
    "def _get_features_for_type_mod(column_type):\n",
    "    \"\"\"\n",
    "    Get features to be generated for a type\n",
    "    \"\"\"\n",
    "    # First get the look up table\n",
    "    lookup_table = py_entitymatching.feature.autofeaturegen._get_feat_lkp_tbl()\n",
    "\n",
    "    # Based on the column type, return the feature functions that should be\n",
    "    # generated.\n",
    "    if column_type == \"str_eq_1w\":\n",
    "        features = lookup_table[\"STR_EQ_1W\"]\n",
    "    elif column_type == \"str_bt_1w_5w\":\n",
    "        features = lookup_table[\"STR_BT_1W_5W\"]\n",
    "    elif column_type == \"str_bt_5w_10w\":\n",
    "        features = lookup_table[\"STR_BT_5W_10W\"]\n",
    "    elif column_type == \"str_gt_10w\":\n",
    "        features = lookup_table[\"STR_GT_10W\"]\n",
    "    elif column_type == \"numeric\":\n",
    "        features = lookup_table[\"NUM\"]\n",
    "    elif column_type == \"boolean\":\n",
    "        features = lookup_table[\"BOOL\"]\n",
    "    elif column_type == \"un_determined\":\n",
    "        features = lookup_table[\"UN_DETERMINED\"]\n",
    "    else:\n",
    "        raise TypeError(\"Unknown type\")\n",
    "    return features\n",
    "\n",
    "\n",
    "# Monkey patching the function.\n",
    "py_entitymatching.feature.autofeaturegen._get_features_for_type = (\n",
    "    _get_features_for_type_mod\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structured_amazon_google\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.6903225806451613, 'recall': 0.45726495726495725, 'f1': 0.5501285347043702}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.6903225806451613, 'recall': 0.45726495726495725, 'f1': 0.5501285347043702}\n",
      "structured_beer\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.7368421052631579, 'recall': 1.0, 'f1': 0.8484848484848484}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.7368421052631579, 'recall': 1.0, 'f1': 0.8484848484848484}\n",
      "structured_dblp_acm\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.9778761061946902, 'recall': 0.9954954954954955, 'f1': 0.9866071428571428}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.9778761061946902, 'recall': 0.9954954954954955, 'f1': 0.9866071428571428}\n",
      "structured_dblp_google_scholar\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.9343955014058107, 'recall': 0.9317757009345794, 'f1': 0.933083762283575}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.9343955014058107, 'recall': 0.9317757009345794, 'f1': 0.933083762283575}\n",
      "structured_fodors_zagat\n",
      "training...\n",
      "training...done\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "structured_walmart_amazon\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.8717948717948718, 'recall': 0.5284974093264249, 'f1': 0.6580645161290322}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.8717948717948718, 'recall': 0.5284974093264249, 'f1': 0.6580645161290322}\n",
      "structured_itunes_amazon\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.8387096774193549, 'recall': 0.9629629629629629, 'f1': 0.896551724137931}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.8387096774193549, 'recall': 0.9629629629629629, 'f1': 0.896551724137931}\n",
      "dirty_dblp_acm\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.8922413793103449, 'recall': 0.9324324324324325, 'f1': 0.9118942731277534}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.8922413793103449, 'recall': 0.9324324324324325, 'f1': 0.9118942731277534}\n",
      "dirty_dblp_google_scholar\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.8494623655913979, 'recall': 0.8121495327102803, 'f1': 0.8303870043000479}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.8494623655913979, 'recall': 0.8121495327102803, 'f1': 0.8303870043000479}\n",
      "dirty_walmart_amazon\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.725, 'recall': 0.3005181347150259, 'f1': 0.4249084249084249}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.725, 'recall': 0.3005181347150259, 'f1': 0.4249084249084249}\n",
      "dirty_itunes_amazon\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.6086956521739131, 'recall': 0.5185185185185185, 'f1': 0.5599999999999999}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.6086956521739131, 'recall': 0.5185185185185185, 'f1': 0.5599999999999999}\n",
      "textual_abt_buy\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.7941176470588235, 'recall': 0.3932038834951456, 'f1': 0.525974025974026}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.7941176470588235, 'recall': 0.3932038834951456, 'f1': 0.525974025974026}\n",
      "textual_company\n",
      "training...\n",
      "training...done\n",
      "{'precision': 0.6976934068177179, 'recall': 0.6060283687943262, 'f1': 0.6486383907391593}\n",
      "saving...\n",
      "reload test...\n",
      "{'precision': 0.6976934068177179, 'recall': 0.6060283687943262, 'f1': 0.6486383907391593}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import lemon.utils.datasets.deepmatcher\n",
    "import lemon\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    load_dataset_func = getattr(lemon.utils.datasets.deepmatcher, dataset_name)\n",
    "    dataset = load_dataset_func(root=dataset_out_root_dir)\n",
    "    matcher = lemon.utils.matchers.MagellanMatcher()\n",
    "    print(\"training...\")\n",
    "    matcher.fit(\n",
    "        dataset.train.records.a,\n",
    "        dataset.train.records.b,\n",
    "        dataset.train.record_id_pairs,\n",
    "        dataset.train.labels,\n",
    "    )\n",
    "    print(\"training...done\")\n",
    "    eval_result = matcher.evaluate(\n",
    "        dataset.test.records.a,\n",
    "        dataset.test.records.b,\n",
    "        dataset.test.record_id_pairs,\n",
    "        dataset.test.labels,\n",
    "    )\n",
    "    print(eval_result)\n",
    "    print(\"saving...\")\n",
    "    (pathlib.Path(model_out_root_dir) / dataset_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with (pathlib.Path(model_out_root_dir) / dataset_name / \"model.pickle\").open(\n",
    "        \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(matcher, f)\n",
    "    with (pathlib.Path(model_out_root_dir) / dataset_name / \"eval_result.pickle\").open(\n",
    "        \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(eval_result, f)\n",
    "    print(\"reload test...\")\n",
    "    with (pathlib.Path(model_out_root_dir) / dataset_name / \"model.pickle\").open(\n",
    "        \"rb\"\n",
    "    ) as f:\n",
    "        matcher_reload = pickle.load(f)\n",
    "    eval_result_reload = matcher_reload.evaluate(\n",
    "        dataset.test.records.a,\n",
    "        dataset.test.records.b,\n",
    "        dataset.test.record_id_pairs,\n",
    "        dataset.test.labels,\n",
    "    )\n",
    "    print(eval_result_reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
