{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemon のモジュールを利用して、BERT-miniモデルを作成する\n",
    "\n",
    "BERT mini model は 以下の設定\n",
    "* epoch 5 までのモデル\n",
    "* batch size 32,\n",
    "* linearly decreasing learning rate from 3 ^ 10−5 with 50 warmup steps\n",
    "* 16-bit precision optimization\n",
    "* 1, 3, 5, 10, or 20 epochs depending on the dataset size\n",
    "* The final model is the one from the epoch with the highest F1 score on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_out_root_dir = \"../../data/lemon/datasets\"\n",
    "model_out_root_dir = \"../../data/lemon/model/bert-mini\"\n",
    "dataset_names = [\n",
    "    \"structured_amazon_google\",\n",
    "    \"structured_beer\",\n",
    "    \"structured_dblp_acm\",\n",
    "    \"structured_dblp_google_scholar\",\n",
    "    \"structured_fodors_zagat\",\n",
    "    \"structured_walmart_amazon\",\n",
    "    \"structured_itunes_amazon\",\n",
    "    \"dirty_dblp_acm\",\n",
    "    \"dirty_dblp_google_scholar\",\n",
    "    \"dirty_walmart_amazon\",\n",
    "    \"dirty_itunes_amazon\",\n",
    "    \"textual_abt_buy\",\n",
    "    \"textual_company\",\n",
    "]\n",
    "gpu_id = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchモジュールの読み込み前に、利用できるGPUを指定しておく\n",
    "## これをやらないと、システム内のＧＰＵすべてを利用してしまう\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA = True\n",
      "CUDA DEVICES = 1\n",
      "CUDA CURRENT DEVICE_ID =  0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA =\", torch.cuda.is_available())\n",
    "print(\"CUDA DEVICES =\", torch.cuda.device_count())\n",
    "print(\"CUDA CURRENT DEVICE_ID = \", torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seeds and Reproducibility\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch``\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "structured_amazon_google\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 6874\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4300' max='4300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4300/4300 02:02, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.205045</td>\n",
       "      <td>0.529563</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.440171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.176664</td>\n",
       "      <td>0.630021</td>\n",
       "      <td>0.623431</td>\n",
       "      <td>0.636752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.165656</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.175556</td>\n",
       "      <td>0.685225</td>\n",
       "      <td>0.686695</td>\n",
       "      <td>0.683761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.185241</td>\n",
       "      <td>0.688797</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>0.709402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.179734</td>\n",
       "      <td>0.710680</td>\n",
       "      <td>0.651246</td>\n",
       "      <td>0.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.177274</td>\n",
       "      <td>0.696356</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.735043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.196142</td>\n",
       "      <td>0.695297</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.726496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.205477</td>\n",
       "      <td>0.694184</td>\n",
       "      <td>0.618729</td>\n",
       "      <td>0.790598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.229534</td>\n",
       "      <td>0.695327</td>\n",
       "      <td>0.617940</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.713675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.218527</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.670996</td>\n",
       "      <td>0.662393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.228114</td>\n",
       "      <td>0.677355</td>\n",
       "      <td>0.637736</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.237238</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.606838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.250928</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.649573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.653244</td>\n",
       "      <td>0.685446</td>\n",
       "      <td>0.623932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.259899</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.683761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.269149</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.709402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.271916</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.663968</td>\n",
       "      <td>0.700855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.276198</td>\n",
       "      <td>0.672451</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.662393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-215\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-215/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-215/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-215/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-215/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-430\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-430/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-430/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-430/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-430/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-645\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-645/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-645/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-645/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-645/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-860\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-860/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-860/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-860/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-860/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1075\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1075/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1075/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1075/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1075/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1505\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1505/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1505/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1505/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1505/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1720\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1720/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1720/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1720/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1720/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1935\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1935/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1935/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1935/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1935/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2150\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2150/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2150/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2150/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2150/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2365\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2365/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2365/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2365/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2365/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2580\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2580/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2580/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2580/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2580/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2795\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2795/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2795/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2795/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-2795/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3010\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3010/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3010/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3010/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3010/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3225\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3225/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3225/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3225/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3225/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3440\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3440/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3440/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3440/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3440/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3655\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3655/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3655/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3655/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3655/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3870\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3870/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3870/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3870/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-3870/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4085\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4085/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4085/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4085/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4085/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4300\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4300/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4300/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4300/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-4300/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290 (score: 0.7106796116504855).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6642335766423357, 'recall': 0.7777777777777778, 'f1': 0.7165354330708661}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_amazon_google/checkpoints/checkpoint-1290/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2293\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6642335766423357, 'recall': 0.7777777777777778, 'f1': 0.7165354330708661}\n",
      "=============================\n",
      "structured_beer\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 268\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 00:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697697</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.720800</td>\n",
       "      <td>0.588845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.645700</td>\n",
       "      <td>0.476619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.438265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.426094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.413270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.353854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.304806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>0.272030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.246353</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.229381</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.218751</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.207183</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.194265</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.190696</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.191058</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.193354</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.187157</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.187180</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.186534</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-9\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-9/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-9/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-9/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-9/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-18\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-18/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-18/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-18/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-18/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-27\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-27/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-27/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-27/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-27/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-36\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-36/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-36/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-36/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-36/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-45\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-45/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-45/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-45/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-45/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-54\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-54/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-54/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-54/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-54/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-63\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-63/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-63/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-63/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-63/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-72\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-72/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-72/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-72/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-81\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-81/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-81/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-81/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-81/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-90\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-90/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-90/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-90/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-90/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-99\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-99/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-99/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-99/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-99/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-108\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-108/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-108/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-108/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-108/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-117\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-117/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-117/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-117/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-117/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-126\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-126/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-126/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-126/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-126/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-135\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-135/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-135/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-135/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-135/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-144\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-144/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-144/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-144/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-162\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-162/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-162/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-162/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-162/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-171\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-171/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-171/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-171/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-171/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-180\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-180/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-180/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-180/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153 (score: 0.8).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5833333333333334, 'recall': 1.0, 'f1': 0.7368421052631579}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_beer/checkpoints/checkpoint-153/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 91\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5833333333333334, 'recall': 1.0, 'f1': 0.7368421052631579}\n",
      "=============================\n",
      "structured_dblp_acm\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 7417\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4640' max='4640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4640/4640 02:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.065357</td>\n",
       "      <td>0.952596</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>0.950450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.042003</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.960177</td>\n",
       "      <td>0.977477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.048310</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.047152</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.964680</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.032681</td>\n",
       "      <td>0.978771</td>\n",
       "      <td>0.971175</td>\n",
       "      <td>0.986486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.986486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.045661</td>\n",
       "      <td>0.975391</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>0.974244</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.976641</td>\n",
       "      <td>0.964835</td>\n",
       "      <td>0.988739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.044120</td>\n",
       "      <td>0.974070</td>\n",
       "      <td>0.975169</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.986486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.038414</td>\n",
       "      <td>0.978628</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.039620</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.977629</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.045553</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.045367</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.046828</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.973274</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-232\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-232/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-232/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-232/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-232/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-464\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-464/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-464/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-464/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-464/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-696\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-696/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-696/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-696/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-696/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-928\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-928/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-928/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-928/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-928/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1160\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1160/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1160/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1160/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1160/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1392\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1392/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1392/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1392/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1392/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1624\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1624/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1624/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1624/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1624/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1856\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1856/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1856/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1856/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-1856/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2088\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2088/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2088/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2088/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2088/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2320\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2320/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2320/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2320/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2320/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2552\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2552/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2552/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2552/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2552/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2784\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2784/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2784/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2784/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-2784/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3016\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3016/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3016/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3016/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3016/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3248\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3248/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3248/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3248/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3248/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3480\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3480/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3480/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3480/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3480/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3712\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3712/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3712/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3712/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3712/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4176\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4176/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4176/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4176/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4408\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4408/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4408/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4408/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4408/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4640\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4640/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4640/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4640/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-4640/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944 (score: 0.9809203142536477).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9842342342342343, 'recall': 0.9842342342342343, 'f1': 0.9842342342342343}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_dblp_acm/checkpoints/checkpoint-3944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9842342342342343, 'recall': 0.9842342342342343, 'f1': 0.9842342342342343}\n",
      "=============================\n",
      "structured_dblp_google_scholar\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 17223\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10780' max='10780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10780/10780 05:14, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.097321</td>\n",
       "      <td>0.919596</td>\n",
       "      <td>0.948361</td>\n",
       "      <td>0.892523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.072524</td>\n",
       "      <td>0.934121</td>\n",
       "      <td>0.908930</td>\n",
       "      <td>0.960748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.074255</td>\n",
       "      <td>0.939352</td>\n",
       "      <td>0.917186</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.069579</td>\n",
       "      <td>0.949248</td>\n",
       "      <td>0.954631</td>\n",
       "      <td>0.943925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.075309</td>\n",
       "      <td>0.947658</td>\n",
       "      <td>0.931408</td>\n",
       "      <td>0.964486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.080249</td>\n",
       "      <td>0.948529</td>\n",
       "      <td>0.933092</td>\n",
       "      <td>0.964486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.091971</td>\n",
       "      <td>0.947863</td>\n",
       "      <td>0.952786</td>\n",
       "      <td>0.942991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.093714</td>\n",
       "      <td>0.947220</td>\n",
       "      <td>0.955323</td>\n",
       "      <td>0.939252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.100588</td>\n",
       "      <td>0.946729</td>\n",
       "      <td>0.946729</td>\n",
       "      <td>0.946729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>0.942453</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>0.933645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.120335</td>\n",
       "      <td>0.945212</td>\n",
       "      <td>0.964043</td>\n",
       "      <td>0.927103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.111271</td>\n",
       "      <td>0.950163</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.953271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.130865</td>\n",
       "      <td>0.944733</td>\n",
       "      <td>0.955110</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>0.929907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.943256</td>\n",
       "      <td>0.947664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.137946</td>\n",
       "      <td>0.945642</td>\n",
       "      <td>0.948308</td>\n",
       "      <td>0.942991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.131629</td>\n",
       "      <td>0.951017</td>\n",
       "      <td>0.940585</td>\n",
       "      <td>0.961682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.142384</td>\n",
       "      <td>0.943788</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.933645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.136632</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.948694</td>\n",
       "      <td>0.950467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.137502</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.946828</td>\n",
       "      <td>0.948598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-539\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-539/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-539/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-539/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-539/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1078\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1078/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1078/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1078/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1078/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1617\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1617/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1617/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1617/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-1617/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2156\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2156/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2156/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2156/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2156/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2695\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2695/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2695/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2695/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-2695/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3234\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3234/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3234/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3234/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3234/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3773\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3773/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3773/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3773/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-3773/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4312\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4312/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4312/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4312/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4312/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4851\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4851/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4851/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4851/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-4851/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5390\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5390/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5390/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5390/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5390/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5929\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5929/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5929/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5929/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-5929/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-6468\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-6468/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-6468/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-6468/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-6468/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7007\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7007/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7007/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7007/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7007/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7546\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7546/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7546/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7546/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-7546/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8085\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8085/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8085/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8085/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8085/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8624\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8624/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8624/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8624/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-8624/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9702\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9702/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9702/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9702/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9702/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10241\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10241/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10241/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10241/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10241/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10780\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10780/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10780/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10780/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-10780/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163 (score: 0.9510166358595193).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9343664539653601, 'recall': 0.9579439252336449, 'f1': 0.9460083064143978}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_dblp_google_scholar/checkpoints/checkpoint-9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9343664539653601, 'recall': 0.9579439252336449, 'f1': 0.9460083064143978}\n",
      "=============================\n",
      "structured_fodors_zagat\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 567\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 00:13, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.593497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.383444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.334352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.229094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.075395</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.040240</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.056560</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.037159</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.040902</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.060470</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-18\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-18/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-18/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-18/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-18/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-36\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-36/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-36/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-36/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-36/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-54\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-54/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-54/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-54/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-54/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-72\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-72/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-72/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-72/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-90\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-90/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-90/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-90/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-90/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-108\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-108/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-108/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-108/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-108/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-126\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-126/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-126/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-126/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-126/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-162\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-162/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-162/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-162/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-162/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-180\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-180/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-180/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-180/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-180/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-198\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-198/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-198/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-198/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-198/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-216\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-216/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-216/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-216/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-216/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-234\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-234/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-234/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-234/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-234/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-252\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-252/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-252/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-252/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-252/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-270\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-270/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-270/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-270/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-270/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-288\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-288/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-288/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-288/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-288/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-306\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-306/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-306/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-306/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-306/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-324\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-324/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-324/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-324/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-324/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-342\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-342/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-342/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-342/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-342/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 190\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-360\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-360/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-360/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-360/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-360/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144 (score: 0.9777777777777777).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 189\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 0.9545454545454546, 'f1': 0.9767441860465117}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_fodors_zagat/checkpoints/checkpoint-144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 189\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 0.9545454545454546, 'f1': 0.9767441860465117}\n",
      "=============================\n",
      "structured_walmart_amazon\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 6144\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3840' max='3840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3840/3840 01:55, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.188023</td>\n",
       "      <td>0.657825</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.642487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.132691</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>0.818653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.123130</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.756477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.134115</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.746114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.757370</td>\n",
       "      <td>0.673387</td>\n",
       "      <td>0.865285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.722467</td>\n",
       "      <td>0.849741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>0.790361</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.849741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.183607</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.870466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.169929</td>\n",
       "      <td>0.798030</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.201277</td>\n",
       "      <td>0.773893</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.860104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.823834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.210591</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.731278</td>\n",
       "      <td>0.860104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.183763</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.803109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.213342</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.854922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.216036</td>\n",
       "      <td>0.796020</td>\n",
       "      <td>0.765550</td>\n",
       "      <td>0.829016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.215325</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.808290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.778043</td>\n",
       "      <td>0.721239</td>\n",
       "      <td>0.844560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.813472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.225513</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.755869</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.225376</td>\n",
       "      <td>0.798030</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-192\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-192/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-192/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-192/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-192/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-384\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-384/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-384/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-384/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-384/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-576\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-576/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-576/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-576/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-576/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-768\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-768/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-768/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-768/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-768/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-960\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-960/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-960/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-960/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-960/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1152\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1152/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1152/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1152/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1152/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1344\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1344/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1344/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1344/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1344/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1536\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1536/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1536/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1536/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1728\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1728/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1728/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1728/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1728/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1920\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1920/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1920/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1920/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-1920/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2112\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2112/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2112/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2112/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2112/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2304\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2304/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2304/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2304/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2304/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2688\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2688/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2688/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2688/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2688/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2880\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2880/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2880/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2880/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2880/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3072\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3072/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3072/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3072/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3264\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3264/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3264/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3264/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3264/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3456\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3456/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3456/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3456/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3456/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3648\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3648/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3648/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3840\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3840/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3840/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3840/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-3840/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496 (score: 0.8115183246073298).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8241758241758241, 'recall': 0.7772020725388601, 'f1': 0.8}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_walmart_amazon/checkpoints/checkpoint-2496/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8241758241758241, 'recall': 0.7772020725388601, 'f1': 0.8}\n",
      "=============================\n",
      "structured_itunes_amazon\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 321\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 00:10, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.677378</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648900</td>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.555500</td>\n",
       "      <td>0.540179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.491340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.400731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.329969</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.287391</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.238446</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.219264</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.205636</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.201568</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.207640</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.197249</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.212588</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.201393</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.214104</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.212834</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.208036</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-11\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-11/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-11/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-11/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-11/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-22\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-22/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-22/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-22/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-22/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-33\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-33/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-33/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-33/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-33/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-44\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-44/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-44/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-44/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-44/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-55\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-55/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-55/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-55/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-55/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-66\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-66/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-66/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-66/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-66/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-77\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-77/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-77/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-77/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-77/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-99\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-99/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-99/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-99/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-99/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-110\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-110/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-110/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-110/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-110/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-121\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-121/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-121/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-121/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-121/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-132\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-132/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-132/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-132/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-132/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-143\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-143/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-143/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-143/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-143/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-154\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-154/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-154/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-154/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-154/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-165\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-165/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-165/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-165/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-165/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-176\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-176/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-176/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-176/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-187\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-187/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-187/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-187/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-187/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-198\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-198/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-198/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-198/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-198/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-209\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-209/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-209/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-209/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-209/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-220\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-220/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-220/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-220/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-220/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88 (score: 0.8813559322033898).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8387096774193549, 'recall': 0.9629629629629629, 'f1': 0.896551724137931}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/structured_itunes_amazon/checkpoints/checkpoint-88/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8387096774193549, 'recall': 0.9629629629629629, 'f1': 0.896551724137931}\n",
      "=============================\n",
      "dirty_dblp_acm\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 7417\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4640' max='4640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4640/4640 02:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.062872</td>\n",
       "      <td>0.955257</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.961712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.051785</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.986486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.049818</td>\n",
       "      <td>0.968958</td>\n",
       "      <td>0.954148</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.058948</td>\n",
       "      <td>0.965670</td>\n",
       "      <td>0.949891</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>0.970917</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.977477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.045744</td>\n",
       "      <td>0.972129</td>\n",
       "      <td>0.962472</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.055521</td>\n",
       "      <td>0.967956</td>\n",
       "      <td>0.950108</td>\n",
       "      <td>0.986486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.056251</td>\n",
       "      <td>0.973274</td>\n",
       "      <td>0.962555</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.046247</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>0.977477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.046960</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>0.977477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.963776</td>\n",
       "      <td>0.940043</td>\n",
       "      <td>0.988739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.974244</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.055409</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.056725</td>\n",
       "      <td>0.976536</td>\n",
       "      <td>0.968958</td>\n",
       "      <td>0.984234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.056406</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.054921</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.056175</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.058418</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.981982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-232\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-232/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-232/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-232/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-232/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-464\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-464/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-464/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-464/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-464/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-696\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-696/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-696/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-696/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-696/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-928\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-928/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-928/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-928/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-928/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1160\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1160/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1160/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1160/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1160/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1392\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1392/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1392/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1392/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1392/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1624\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1624/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1624/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1624/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1624/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1856\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1856/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1856/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1856/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-1856/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2088\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2088/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2088/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2088/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2088/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2552\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2552/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2552/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2552/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2552/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2784\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2784/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2784/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2784/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2784/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3016\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3016/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3016/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3016/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3016/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3248\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3248/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3248/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3248/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3248/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3480\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3480/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3480/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3480/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3480/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3712\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3712/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3712/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3712/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3712/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3944\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3944/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3944/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3944/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-3944/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4176\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4176/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4176/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4176/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4408\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4408/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4408/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4408/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4408/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4640\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4640/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4640/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4640/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-4640/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320 (score: 0.9774774774774775).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9710467706013363, 'recall': 0.9819819819819819, 'f1': 0.9764837625979844}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_acm/checkpoints/checkpoint-2320/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2473\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9710467706013363, 'recall': 0.9819819819819819, 'f1': 0.9764837625979844}\n",
      "=============================\n",
      "dirty_dblp_google_scholar\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 17223\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10780' max='10780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10780/10780 05:14, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.103827</td>\n",
       "      <td>0.902812</td>\n",
       "      <td>0.956113</td>\n",
       "      <td>0.855140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.077261</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.934701</td>\n",
       "      <td>0.936449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.082416</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.913884</td>\n",
       "      <td>0.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.081727</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.916078</td>\n",
       "      <td>0.969159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.076678</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.943256</td>\n",
       "      <td>0.947664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.091246</td>\n",
       "      <td>0.946168</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.969159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.088188</td>\n",
       "      <td>0.949883</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>0.947664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.090595</td>\n",
       "      <td>0.948196</td>\n",
       "      <td>0.938645</td>\n",
       "      <td>0.957944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.105887</td>\n",
       "      <td>0.943861</td>\n",
       "      <td>0.922391</td>\n",
       "      <td>0.966355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.103383</td>\n",
       "      <td>0.946977</td>\n",
       "      <td>0.942593</td>\n",
       "      <td>0.951402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.114053</td>\n",
       "      <td>0.945269</td>\n",
       "      <td>0.938306</td>\n",
       "      <td>0.952336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.120422</td>\n",
       "      <td>0.943112</td>\n",
       "      <td>0.948912</td>\n",
       "      <td>0.937383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.121574</td>\n",
       "      <td>0.950322</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.965421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.134961</td>\n",
       "      <td>0.943236</td>\n",
       "      <td>0.954981</td>\n",
       "      <td>0.931776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.143664</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.923698</td>\n",
       "      <td>0.961682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.137141</td>\n",
       "      <td>0.945657</td>\n",
       "      <td>0.939982</td>\n",
       "      <td>0.951402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.129977</td>\n",
       "      <td>0.946878</td>\n",
       "      <td>0.944238</td>\n",
       "      <td>0.949533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.137774</td>\n",
       "      <td>0.945657</td>\n",
       "      <td>0.939982</td>\n",
       "      <td>0.951402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.943150</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.945794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.142371</td>\n",
       "      <td>0.945116</td>\n",
       "      <td>0.940741</td>\n",
       "      <td>0.949533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-539\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-539/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-539/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-539/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-539/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1078\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1078/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1078/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1078/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1078/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1617\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1617/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1617/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1617/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-1617/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2156\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2156/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2156/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2156/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2156/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2695\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2695/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2695/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2695/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-2695/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3234\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3234/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3234/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3234/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3234/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3773\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3773/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3773/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3773/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-3773/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4312\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4312/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4312/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4312/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4312/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4851\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4851/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4851/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4851/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-4851/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5390\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5390/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5390/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5390/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5390/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5929\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5929/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5929/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5929/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-5929/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-6468\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-6468/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-6468/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-6468/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-6468/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7546\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7546/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7546/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7546/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7546/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8085\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8085/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8085/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8085/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8085/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8624\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8624/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8624/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8624/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-8624/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9163\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9163/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9163/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9163/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9163/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9702\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9702/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9702/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9702/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-9702/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10241\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10241/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10241/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10241/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10241/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10780\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10780/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10780/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10780/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-10780/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007 (score: 0.9503219871205152).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9322493224932249, 'recall': 0.9644859813084112, 'f1': 0.9480937069361507}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/dirty_dblp_google_scholar/checkpoints/checkpoint-7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5742\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9322493224932249, 'recall': 0.9644859813084112, 'f1': 0.9480937069361507}\n",
      "=============================\n",
      "dirty_walmart_amazon\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 6144\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3840' max='3840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3840/3840 01:54, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>0.189859</td>\n",
       "      <td>0.654450</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>0.647668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.708520</td>\n",
       "      <td>0.818653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.132392</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.735751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>0.776350</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.782383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.135127</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.797927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.159461</td>\n",
       "      <td>0.772947</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.829016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.178855</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.172283</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.844560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.187913</td>\n",
       "      <td>0.762353</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.181708</td>\n",
       "      <td>0.778055</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.808290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.188997</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.813472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.214887</td>\n",
       "      <td>0.781991</td>\n",
       "      <td>0.720524</td>\n",
       "      <td>0.854922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.188012</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.803109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.226899</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.714912</td>\n",
       "      <td>0.844560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.214440</td>\n",
       "      <td>0.796069</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.210396</td>\n",
       "      <td>0.798995</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.823834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.237102</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.238478</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.233328</td>\n",
       "      <td>0.787286</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-192\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-192/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-192/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-192/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-192/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-384\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-384/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-384/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-384/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-384/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-576\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-576/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-576/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-576/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-576/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-768\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-768/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-768/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-768/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-768/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-960\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-960/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-960/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-960/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-960/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1152\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1152/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1152/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1152/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1152/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1344\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1344/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1344/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1344/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1344/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1536\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1536/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1536/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1536/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1728\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1728/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1728/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1728/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1728/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1920\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1920/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1920/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1920/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-1920/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2112\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2112/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2112/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2112/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2112/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2304\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2304/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2304/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2304/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2304/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2688\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2688/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2688/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2688/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2688/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2880\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2880/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2880/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2880/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2880/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3072\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3072/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3072/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3072/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3264\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3264/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3264/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3264/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3264/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3456\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3456/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3456/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3456/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3456/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3648\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3648/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3648/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3840\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3840/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3840/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3840/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-3840/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496 (score: 0.8136482939632546).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.827027027027027, 'recall': 0.7927461139896373, 'f1': 0.8095238095238094}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/dirty_walmart_amazon/checkpoints/checkpoint-2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2049\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.827027027027027, 'recall': 0.7927461139896373, 'f1': 0.8095238095238094}\n",
      "=============================\n",
      "dirty_itunes_amazon\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 321\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 00:10, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.676380</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.584827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.542023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.491534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.403135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.330833</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.290032</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.238002</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.207472</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.199581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.192015</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.191417</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.202072</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.170151</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.196580</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.188183</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.189460</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.200443</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.199156</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-11\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-11/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-11/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-11/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-11/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-22\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-22/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-22/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-22/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-22/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-33\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-33/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-33/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-33/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-33/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-44\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-44/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-44/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-44/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-44/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-55\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-55/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-55/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-55/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-55/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-66\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-66/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-66/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-66/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-66/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-77\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-77/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-77/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-77/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-77/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-88\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-88/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-88/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-88/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-99\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-99/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-99/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-99/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-99/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-110\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-110/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-110/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-110/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-110/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-121\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-121/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-121/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-121/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-121/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-132\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-132/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-132/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-132/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-132/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-143\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-143/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-143/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-143/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-143/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-165\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-165/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-165/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-165/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-165/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-176\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-176/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-176/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-176/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-187\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-187/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-187/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-187/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-187/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-198\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-198/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-198/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-198/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-198/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-209\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-209/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-209/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-209/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-209/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-220\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-220/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-220/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-220/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-220/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154 (score: 0.9).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8125, 'recall': 0.9629629629629629, 'f1': 0.8813559322033898}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/dirty_itunes_amazon/checkpoints/checkpoint-154/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 109\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8125, 'recall': 0.9629629629629629, 'f1': 0.8813559322033898}\n",
      "=============================\n",
      "textual_abt_buy\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 5743\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3600/3600 01:53, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.167457</td>\n",
       "      <td>0.701176</td>\n",
       "      <td>0.680365</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>0.799054</td>\n",
       "      <td>0.778802</td>\n",
       "      <td>0.820388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.747573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.114675</td>\n",
       "      <td>0.817955</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.128118</td>\n",
       "      <td>0.815668</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.859223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.154777</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.747573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.153357</td>\n",
       "      <td>0.816537</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.766990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.844660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.147034</td>\n",
       "      <td>0.823219</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.757282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.141984</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.146206</td>\n",
       "      <td>0.862155</td>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.834951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>0.832487</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.159257</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.820388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.177553</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.177723</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.178566</td>\n",
       "      <td>0.838046</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.791262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.178367</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.800971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.189790</td>\n",
       "      <td>0.841558</td>\n",
       "      <td>0.905028</td>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.190454</td>\n",
       "      <td>0.842377</td>\n",
       "      <td>0.900552</td>\n",
       "      <td>0.791262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-180\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-180/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-180/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-180/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-180/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-360\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-360/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-360/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-360/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-540\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-540/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-540/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-540/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-540/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-720\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-720/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-720/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-720/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-720/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-900\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-900/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-900/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1080\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1080/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1080/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1080/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1080/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1260\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1260/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1260/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1260/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1260/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1440\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1440/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1440/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1440/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1440/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1620\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1620/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1620/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1620/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1620/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1800\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1800/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1800/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2160\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2160/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2160/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2160/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2160/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2340\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2340/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2340/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2340/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2340/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2520\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2520/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2520/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2520/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2520/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2700\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2700/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2700/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2700/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2880\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2880/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2880/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2880/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-2880/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3060\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3060/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3060/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3060/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3060/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3240\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3240/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3240/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3240/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3240/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3420\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3420/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3420/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3420/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3420/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3600\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3600/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-3600/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980 (score: 0.8621553884711779).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8177570093457944, 'recall': 0.8495145631067961, 'f1': 0.8333333333333333}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/textual_abt_buy/checkpoints/checkpoint-1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1916\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8177570093457944, 'recall': 0.8495145631067961, 'f1': 0.8333333333333333}\n",
      "=============================\n",
      "textual_company\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/vocab.txt from cache at /home/hironori/.cache/huggingface/transformers/b9f9ef46c5d893ee76a6e52cb006e301b6aa7c19d8cd1d7acb7acd09e11039c3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/config.json from cache at /home/hironori/.cache/huggingface/transformers/d4bb65fac1f629b879ae238c27022568307f79a7aa4d55060745f828812b4dd0.2bbf3a8935447a5e3abcc0d62367c14e846bd3595ebb28a305e457ad1d24ff8f\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/bert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin from cache at /home/hironori/.cache/huggingface/transformers/dcc42b340ea5a080f1a13132f5978e80ce76130d35af320cad1c27c268a3dffa.ff15e5badd62fb8a20e8c848b63297b6fce289d7feebdd3bcd8dc516c4df22d5\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 67596\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42260' max='42260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42260/42260 22:50, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.204612</td>\n",
       "      <td>0.842067</td>\n",
       "      <td>0.871458</td>\n",
       "      <td>0.814594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.208816</td>\n",
       "      <td>0.840770</td>\n",
       "      <td>0.905138</td>\n",
       "      <td>0.784950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.231617</td>\n",
       "      <td>0.840256</td>\n",
       "      <td>0.904878</td>\n",
       "      <td>0.784248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.248359</td>\n",
       "      <td>0.837884</td>\n",
       "      <td>0.904288</td>\n",
       "      <td>0.780565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.286417</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.877850</td>\n",
       "      <td>0.810560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.314467</td>\n",
       "      <td>0.836202</td>\n",
       "      <td>0.850381</td>\n",
       "      <td>0.822487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.320258</td>\n",
       "      <td>0.834587</td>\n",
       "      <td>0.863466</td>\n",
       "      <td>0.807578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.362015</td>\n",
       "      <td>0.824223</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>0.748465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.388115</td>\n",
       "      <td>0.831748</td>\n",
       "      <td>0.888070</td>\n",
       "      <td>0.782143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.393575</td>\n",
       "      <td>0.833623</td>\n",
       "      <td>0.870986</td>\n",
       "      <td>0.799333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.452198</td>\n",
       "      <td>0.828255</td>\n",
       "      <td>0.883499</td>\n",
       "      <td>0.779512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.478984</td>\n",
       "      <td>0.827188</td>\n",
       "      <td>0.881524</td>\n",
       "      <td>0.779162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.490527</td>\n",
       "      <td>0.827733</td>\n",
       "      <td>0.873709</td>\n",
       "      <td>0.786353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>0.824993</td>\n",
       "      <td>0.891446</td>\n",
       "      <td>0.767760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.529545</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>0.871581</td>\n",
       "      <td>0.788107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.527968</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0.875707</td>\n",
       "      <td>0.787230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.553230</td>\n",
       "      <td>0.823771</td>\n",
       "      <td>0.879833</td>\n",
       "      <td>0.774426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.565094</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.874291</td>\n",
       "      <td>0.784424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.576096</td>\n",
       "      <td>0.821033</td>\n",
       "      <td>0.883411</td>\n",
       "      <td>0.766883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.581051</td>\n",
       "      <td>0.823650</td>\n",
       "      <td>0.879331</td>\n",
       "      <td>0.774601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-2113\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-2113/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-2113/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-2113/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-2113/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-4226\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-4226/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-4226/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-4226/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-4226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-6339\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-6339/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-6339/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-6339/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-6339/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-8452\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-8452/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-8452/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-8452/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-8452/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-12678\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-12678/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-12678/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-12678/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-12678/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-14791\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-14791/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-14791/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-14791/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-14791/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-16904\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-16904/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-16904/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-16904/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-16904/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-19017\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-19017/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-19017/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-19017/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-19017/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-21130\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-21130/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-21130/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-21130/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-21130/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-23243\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-23243/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-23243/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-23243/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-23243/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-25356\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-25356/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-25356/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-25356/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-25356/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-27469\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-27469/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-27469/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-27469/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-27469/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-29582\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-29582/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-29582/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-29582/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-29582/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-31695\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-31695/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-31695/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-31695/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-31695/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-33808\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-33808/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-33808/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-33808/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-33808/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-35921\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-35921/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-35921/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-35921/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-35921/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-38034\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-38034/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-38034/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-38034/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-38034/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-40147\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-40147/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-40147/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-40147/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-40147/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22533\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-42260\n",
      "Configuration saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-42260/config.json\n",
      "Model weights saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-42260/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-42260/tokenizer_config.json\n",
      "Special tokens file saved in ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-42260/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565 (score: 0.8428636570907433).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 22503\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-256_A-4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/added_tokens.json. We won't load it.\n",
      "loading file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/vocab.txt\n",
      "loading file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/tokenizer.json\n",
      "loading file None\n",
      "loading file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/special_tokens_map.json\n",
      "loading file ../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8327693677649154, 'recall': 0.8290780141843972, 'f1': 0.8309195912927589}\n",
      "reload test...\n",
      "../../data/lemon/model/bert-mini/textual_company/checkpoints/checkpoint-10565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp fp16 backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 22503\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8327693677649154, 'recall': 0.8290780141843972, 'f1': 0.8309195912927589}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import lemon.utils.datasets.deepmatcher\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers.trainer_callback import TrainerState\n",
    "\n",
    "\n",
    "def get_best_model_checkpoint_dir(checkpoints_dir_path: pathlib.Path):\n",
    "    last_checkpoints_dir = sorted(\n",
    "        checkpoints_dir_path.iterdir(), key=lambda x: int(str(x).split(\"-\")[-1])\n",
    "    )[-1]\n",
    "    state = TrainerState.load_from_json(\n",
    "        f\"{str(last_checkpoints_dir)}/trainer_state.json\"\n",
    "    )\n",
    "    return pathlib.Path((state.best_model_checkpoint))\n",
    "\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(\"=============================\")\n",
    "    print(dataset_name)\n",
    "    print(\"=============================\")\n",
    "    load_dataset_func = getattr(lemon.utils.datasets.deepmatcher, dataset_name)\n",
    "    dataset = load_dataset_func(dataset_out_root_dir)\n",
    "    output_dir_path = (\n",
    "        pathlib.Path(model_out_root_dir) / dataset_name\n",
    "    )\n",
    "    output_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    matcher = lemon.utils.matchers.TransformerMatcher(\n",
    "        \"google/bert_uncased_L-4_H-256_A-4\",\n",
    "        tokenizer_args={\"model_max_length\": 256},\n",
    "        training_args={\n",
    "            \"output_dir\": str(output_dir_path / \"checkpoints\"),\n",
    "            \"logging_dir\": str(output_dir_path / \"logs\"),\n",
    "            \"per_device_train_batch_size\": 32,\n",
    "            \"learning_rate\": 3e-5,\n",
    "            \"warmup_steps\": 50,\n",
    "            \"fp16\": True,\n",
    "            \"num_train_epochs\": 20,\n",
    "        },\n",
    "    )\n",
    "    print(\"training...\")\n",
    "    ret = matcher.fit(\n",
    "        dataset.train.records.a,\n",
    "        dataset.train.records.b,\n",
    "        dataset.train.record_id_pairs,\n",
    "        dataset.train.labels,\n",
    "        dataset.val.record_id_pairs,\n",
    "        dataset.val.labels,\n",
    "    )\n",
    "    display(ret)\n",
    "    print(\"training...done\")\n",
    "    eval_result = matcher.evaluate(\n",
    "        dataset.test.records.a,\n",
    "        dataset.test.records.b,\n",
    "        dataset.test.record_id_pairs,\n",
    "        dataset.test.labels,\n",
    "    )\n",
    "    print(eval_result)\n",
    "    with (output_dir_path / \"eval_result.pickle\").open(\n",
    "        \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(eval_result, f)\n",
    "    print(\"reload test...\")\n",
    "    print(get_best_model_checkpoint_dir(output_dir_path / \"checkpoints\"))\n",
    "    bert_mini_model_reload = AutoModelForSequenceClassification.from_pretrained(\n",
    "        get_best_model_checkpoint_dir(output_dir_path / \"checkpoints\")\n",
    "    )\n",
    "    matcher_reload = lemon.utils.matchers.TransformerMatcher(bert_mini_model_reload)\n",
    "    eval_result_reload = matcher_reload.evaluate(\n",
    "        dataset.test.records.a,\n",
    "        dataset.test.records.b,\n",
    "        dataset.test.record_id_pairs,\n",
    "        dataset.test.labels,\n",
    "    )\n",
    "    print(eval_result_reload)\n",
    "    assert eval_result == eval_result_reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
